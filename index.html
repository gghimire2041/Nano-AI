<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Models Architecture Showcase</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
            line-height: 1.6;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }

        .header {
            text-align: center;
            margin-bottom: 3rem;
            color: white;
        }

        .header h1 {
            font-size: 3rem;
            font-weight: 700;
            margin-bottom: 1rem;
        }

        .header p {
            font-size: 1.2rem;
            opacity: 0.9;
            max-width: 600px;
            margin: 0 auto;
        }

        .models-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
            gap: 2rem;
        }

        .model-card {
            background: white;
            border-radius: 16px;
            overflow: hidden;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
            transition: transform 0.3s ease;
        }

        .model-card:hover {
            transform: translateY(-5px);
        }

        .card-header {
            padding: 2rem;
            background: var(--primary-color);
            color: white;
            text-align: center;
        }

        .model-icon {
            font-size: 3rem;
            margin-bottom: 1rem;
        }

        .model-title {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        .model-company {
            font-size: 1rem;
            opacity: 0.9;
            margin-bottom: 1rem;
        }

        .architecture-type {
            background: rgba(255, 255, 255, 0.2);
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 500;
        }

        .card-content {
            padding: 2rem;
        }

        .description {
            font-size: 1rem;
            margin-bottom: 2rem;
            color: #555;
        }

        .section {
            margin-bottom: 2rem;
        }

        .section-title {
            font-size: 1.2rem;
            font-weight: 600;
            color: var(--primary-color);
            margin-bottom: 1rem;
            border-bottom: 2px solid var(--primary-color);
            padding-bottom: 0.5rem;
        }

        .process-flow {
            background: #f8fafc;
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
        }

        .flow-step {
            display: flex;
            align-items: center;
            padding: 1rem;
            margin-bottom: 0.5rem;
            background: white;
            border-radius: 8px;
            border-left: 4px solid var(--primary-color);
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        .step-number {
            background: var(--primary-color);
            color: white;
            width: 32px;
            height: 32px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 1rem;
            font-weight: 600;
            font-size: 0.9rem;
        }

        .step-text {
            font-size: 0.95rem;
            font-weight: 500;
        }

        .innovations-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
            gap: 1rem;
        }

        .innovation-card {
            background: #f8fafc;
            padding: 1.5rem;
            border-radius: 12px;
            border-top: 4px solid var(--primary-color);
        }

        .innovation-title {
            font-size: 1rem;
            font-weight: 600;
            color: var(--primary-color);
            margin-bottom: 0.5rem;
        }

        .innovation-desc {
            font-size: 0.9rem;
            color: #666;
        }

        .specs-table {
            background: #f8fafc;
            border-radius: 12px;
            overflow: hidden;
            margin-bottom: 1.5rem;
        }

        .specs-table table {
            width: 100%;
            border-collapse: collapse;
        }

        .specs-table th {
            background: var(--primary-color);
            color: white;
            padding: 1rem;
            text-align: left;
            font-weight: 600;
        }

        .specs-table td {
            padding: 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .specs-table tr:nth-child(even) {
            background: white;
        }

        .chat-button {
            background: var(--primary-color);
            color: white;
            border: none;
            padding: 1rem 2rem;
            border-radius: 25px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            width: 100%;
            transition: all 0.3s ease;
        }

        .chat-button:hover {
            transform: scale(1.05);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.2);
        }

        /* Model-specific colors */
        .chatgpt { --primary-color: #10a37f; }
        .grok { --primary-color: #1d9bf0; }
        .gemini { --primary-color: #4285f4; }
        .deepseek { --primary-color: #ff6b6b; }
        .claude { --primary-color: #d97706; }

        /* Chat Modal */
        .chat-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            z-index: 1000;
        }

        .chat-container {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 90%;
            max-width: 700px;
            height: 80vh;
            background: white;
            border-radius: 16px;
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .chat-header {
            background: var(--chat-color, #333);
            color: white;
            padding: 1.5rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .chat-header h3 {
            font-size: 1.3rem;
            font-weight: 600;
        }

        .close-btn {
            background: none;
            border: none;
            color: white;
            font-size: 1.5rem;
            cursor: pointer;
            padding: 0.5rem;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .close-btn:hover {
            background: rgba(255, 255, 255, 0.2);
        }

        .chat-messages {
            flex: 1;
            padding: 1.5rem;
            overflow-y: auto;
            background: #f8fafc;
        }

        .message {
            margin-bottom: 1rem;
        }

        .message.user {
            text-align: right;
        }

        .message-bubble {
            display: inline-block;
            max-width: 70%;
            padding: 1rem 1.5rem;
            border-radius: 20px;
            font-size: 0.95rem;
        }

        .message.user .message-bubble {
            background: var(--chat-color, #333);
            color: white;
            border-bottom-right-radius: 5px;
        }

        .message.bot .message-bubble {
            background: white;
            color: #333;
            border-bottom-left-radius: 5px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        .chat-input-container {
            padding: 1.5rem;
            background: white;
            border-top: 1px solid #e2e8f0;
        }

        .chat-input-group {
            display: flex;
            gap: 1rem;
        }

        .chat-input {
            flex: 1;
            padding: 0.75rem 1rem;
            border: 2px solid #e2e8f0;
            border-radius: 25px;
            outline: none;
            font-size: 0.95rem;
        }

        .chat-input:focus {
            border-color: var(--chat-color, #333);
        }

        .send-btn {
            background: var(--chat-color, #333);
            color: white;
            border: none;
            padding: 0.75rem 1.5rem;
            border-radius: 25px;
            cursor: pointer;
            font-weight: 600;
        }

        .send-btn:hover {
            opacity: 0.9;
        }

        .typing-indicator {
            display: none;
            padding: 1rem 1.5rem;
            color: #666;
            font-style: italic;
        }

        @media (max-width: 768px) {
            .models-grid {
                grid-template-columns: 1fr;
            }
            
            .header h1 {
                font-size: 2rem;
            }
            
            .innovations-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ü§ñ AI Architecture Showcase</h1>
            <p>Explore the unique architectures behind the world's most advanced AI systems. Experience simulated neural network outputs from miniature models trained on character-level patterns!</p>
        </div>

        <div class="models-grid">
            <!-- ChatGPT -->
            <div class="model-card chatgpt">
                <div class="card-header">
                    <div class="model-icon">üß†</div>
                    <div class="model-title">ChatGPT</div>
                    <div class="model-company">OpenAI</div>
                    <div class="architecture-type">Decoder-only Transformer + RLHF</div>
                </div>
                <div class="card-content">
                    <div class="description">
                        Revolutionary conversational AI using GPT's autoregressive architecture enhanced with Reinforcement Learning from Human Feedback (RLHF) for alignment and safety.
                    </div>

                    <div class="section">
                        <div class="section-title">üèóÔ∏è Architecture Flow</div>
                        <div class="process-flow">
                            <div class="flow-step">
                                <div class="step-number">1</div>
                                <div class="step-text">Input Token Embedding + Positional Encoding</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">2</div>
                                <div class="step-text">Pre-LayerNorm ‚Üí Multi-Head Self-Attention</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">3</div>
                                <div class="step-text">Residual Connection + Pre-LayerNorm</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">4</div>
                                <div class="step-text">Feed-Forward Network (GELU Activation)</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">5</div>
                                <div class="step-text">Output Layer ‚Üí Next Token Prediction</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">üîß Key Innovations</div>
                        <div class="innovations-grid">
                            <div class="innovation-card">
                                <div class="innovation-title">Pre-Layer Normalization</div>
                                <div class="innovation-desc">Applies LayerNorm before attention/FFN blocks for better gradient flow and training stability.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">GELU Activation</div>
                                <div class="innovation-desc">Gaussian Error Linear Units provide smoother, probabilistic activation compared to ReLU.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">RLHF Training</div>
                                <div class="innovation-desc">Reinforcement Learning from Human Feedback aligns model outputs with human preferences.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Causal Masking</div>
                                <div class="innovation-desc">Ensures autoregressive generation - each token only attends to previous tokens.</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">üìä Technical Specifications</div>
                        <div class="specs-table">
                            <table>
                                <thead>
                                    <tr>
                                        <th>Component</th>
                                        <th>Specification</th>
                                        <th>Purpose</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Architecture</td>
                                        <td>Decoder-only Transformer</td>
                                        <td>Autoregressive text generation</td>
                                    </tr>
                                    <tr>
                                        <td>Attention</td>
                                        <td>Multi-head self-attention</td>
                                        <td>Learn token relationships</td>
                                    </tr>
                                    <tr>
                                        <td>Activation</td>
                                        <td>GELU</td>
                                        <td>Smooth, probabilistic activation</td>
                                    </tr>
                                    <tr>
                                        <td>Training</td>
                                        <td>Supervised + RLHF</td>
                                        <td>Human alignment & safety</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <button class="chat-button" onclick="openChat('chatgpt')">Chat with Mini ChatGPT</button>
                </div>
            </div>

            <!-- Grok -->
            <div class="model-card grok">
                <div class="card-header">
                    <div class="model-icon">‚ö°</div>
                    <div class="model-title">Grok</div>
                    <div class="model-company">xAI</div>
                    <div class="architecture-type">Mixture of Experts (MoE)</div>
                </div>
                <div class="card-content">
                    <div class="description">
                        xAI's Grok features a Mixture of Experts architecture with dynamic expert routing. Uses sparse activation to process information efficiently while maintaining model capacity.
                    </div>

                    <div class="section">
                        <div class="section-title">‚ö° MoE Architecture Flow</div>
                        <div class="process-flow">
                            <div class="flow-step">
                                <div class="step-number">1</div>
                                <div class="step-text">Input Processing & Token Embedding</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">2</div>
                                <div class="step-text">Gating Network - Expert Selection</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">3</div>
                                <div class="step-text">Top-K Expert Activation (Sparse)</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">4</div>
                                <div class="step-text">Weighted Expert Output Combination</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">5</div>
                                <div class="step-text">Final Prediction Generation</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">üîß Key Innovations</div>
                        <div class="innovations-grid">
                            <div class="innovation-card">
                                <div class="innovation-title">Expert Routing</div>
                                <div class="innovation-desc">Dynamic routing to specialized expert networks based on input context.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Sparse Activation</div>
                                <div class="innovation-desc">Only activates top-k experts per token, improving efficiency.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Load Balancing</div>
                                <div class="innovation-desc">Ensures even expert utilization for optimal performance.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Gating Network</div>
                                <div class="innovation-desc">Learned routing decisions for optimal expert selection.</div>
                            </div>
                        </div>
                    </div>

                    <button class="chat-button" onclick="openChat('grok')">Chat with Mini Grok</button>
                </div>
            </div>

            <!-- Gemini -->
            <div class="model-card gemini">
                <div class="card-header">
                    <div class="model-icon">üíé</div>
                    <div class="model-title">Gemini</div>
                    <div class="model-company">Google</div>
                    <div class="architecture-type">Multimodal Transformer</div>
                </div>
                <div class="card-content">
                    <div class="description">
                        Google's Gemini is designed as a multimodal AI system that can understand and generate text, images, and code through unified transformer architecture.
                    </div>

                    <div class="section">
                        <div class="section-title">üíé Multimodal Flow</div>
                        <div class="process-flow">
                            <div class="flow-step">
                                <div class="step-number">1</div>
                                <div class="step-text">Multimodal Input Encoding</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">2</div>
                                <div class="step-text">Cross-Modal Attention Layers</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">3</div>
                                <div class="step-text">Unified Embedding Space</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">4</div>
                                <div class="step-text">Multi-Query Attention Processing</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">5</div>
                                <div class="step-text">Multimodal Output Generation</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">üîß Key Innovations</div>
                        <div class="innovations-grid">
                            <div class="innovation-card">
                                <div class="innovation-title">Multi-Query Attention</div>
                                <div class="innovation-desc">Shared key-value pairs across attention heads for efficiency.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">SwiGLU Activation</div>
                                <div class="innovation-desc">Gated linear unit with SiLU activation for better performance.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">RoPE Encoding</div>
                                <div class="innovation-desc">Rotary position encoding for better length generalization.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Cross-Modal Processing</div>
                                <div class="innovation-desc">Unified attention across different input modalities.</div>
                            </div>
                        </div>
                    </div>

                    <button class="chat-button" onclick="openChat('gemini')">Chat with Mini Gemini</button>
                </div>
            </div>

            <!-- DeepSeek -->
            <div class="model-card deepseek">
                <div class="card-header">
                    <div class="model-icon">üîç</div>
                    <div class="model-title">DeepSeek</div>
                    <div class="model-company">DeepSeek AI</div>
                    <div class="architecture-type">Optimized MoE + Reasoning</div>
                </div>
                <div class="card-content">
                    <div class="description">
                        DeepSeek combines optimized Mixture of Experts with advanced reasoning capabilities, featuring improved expert routing and load balancing for efficient inference.
                    </div>

                    <div class="section">
                        <div class="section-title">üîç Optimized MoE Flow</div>
                        <div class="process-flow">
                            <div class="flow-step">
                                <div class="step-number">1</div>
                                <div class="step-text">Enhanced Input Processing</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">2</div>
                                <div class="step-text">Noise-Injected Expert Gating</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">3</div>
                                <div class="step-text">Load-Balanced Expert Selection</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">4</div>
                                <div class="step-text">Reasoning-Optimized Processing</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">5</div>
                                <div class="step-text">Optimized Response Generation</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">üîß Key Innovations</div>
                        <div class="innovations-grid">
                            <div class="innovation-card">
                                <div class="innovation-title">Advanced Load Balancing</div>
                                <div class="innovation-desc">Sophisticated expert utilization tracking and balancing.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Noise Injection</div>
                                <div class="innovation-desc">Training-time noise for better expert exploration.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Reasoning Optimization</div>
                                <div class="innovation-desc">Specialized modules for complex reasoning tasks.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Efficient Routing</div>
                                <div class="innovation-desc">Optimized gating mechanisms for faster inference.</div>
                            </div>
                        </div>
                    </div>

                    <button class="chat-button" onclick="openChat('deepseek')">Chat with Mini DeepSeek</button>
                </div>
            </div>

            <!-- Claude -->
            <div class="model-card claude">
                <div class="card-header">
                    <div class="model-icon">üé≠</div>
                    <div class="model-title">Claude</div>
                    <div class="model-company">Anthropic</div>
                    <div class="architecture-type">Constitutional AI</div>
                </div>
                <div class="card-content">
                    <div class="description">
                        Anthropic's safety-focused AI built with Constitutional AI principles. Features advanced gating mechanisms and built-in harmlessness evaluation for responsible AI behavior.
                    </div>

                    <div class="section">
                        <div class="section-title">üé≠ Constitutional AI Flow</div>
                        <div class="process-flow">
                            <div class="flow-step">
                                <div class="step-number">1</div>
                                <div class="step-text">Input Safety Assessment</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">2</div>
                                <div class="step-text">GLU-Gated Processing</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">3</div>
                                <div class="step-text">Constitutional Principles Check</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">4</div>
                                <div class="step-text">Response Generation</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">5</div>
                                <div class="step-text">Harmlessness Verification</div>
                            </div>
                        </div>
                    </div>

                    <button class="chat-button" onclick="openChat('claude')">Chat with Mini Claude</button>
                </div>
            </div>
        </div>
    </div>

    <!-- Chat Modal -->
    <div id="chatModal" class="chat-modal">
        <div class="chat-container">
            <div class="chat-header">
                <h3 id="chatTitle">Chat with AI</h3>
                <button class="close-btn" onclick="closeChat()">&times;</button>
            </div>
            <div class="chat-messages" id="chatMessages"></div>
            <div class="typing-indicator" id="typingIndicator">
                <span>AI is thinking...</span>
            </div>
            <div class="chat-input-container">
                <div class="chat-input-group">
                    <input type="text" class="chat-input" id="chatInput" placeholder="Type your message...">
                    <button class="send-btn" id="sendBtn" onclick="sendMessage()">Send</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        // ============================================================================
        // GLOBAL VARIABLES AND CONFIGURATION
        // ============================================================================
        
        let currentModel = '';
        const chatHistory = {};

        const modelConfigs = {
            chatgpt: {
                name: 'ChatGPT',
                color: '#10a37f',
                greeting: "Hello! I'm Mini ChatGPT with ~32K parameters (d_model=32, n_heads=2, n_layers=2). I use decoder-only transformer with pre-layer normalization, GELU activations, and RLHF simulation. My tiny neural network creates unique character-level patterns!"
            },
            grok: {
                name: 'Grok',
                color: '#1d9bf0',
                greeting: "Hey! I'm Mini Grok with ~40K parameters using Mixture of Experts (num_experts=2, top_k=2 routing). I have 2 transformer layers with multi-query attention and MoE FFN layers. My expert routing creates distinctive response patterns!"
            },
            gemini: {
                name: 'Gemini',
                color: '#4285f4',
                greeting: "Greetings! I'm Mini Gemini with ~35K parameters (d_model=32, n_heads=2, n_layers=2). I use multi-query attention, rotary position embeddings, and SwiGLU activations. My character-level tokenizer produces unique multimodal-inspired outputs!"
            },
            deepseek: {
                name: 'DeepSeek',
                color: '#ff6b6b',
                greeting: "Hello! I'm Mini DeepSeek with ~40K parameters using optimized MoE (num_experts=2, top_k=2 with load balancing). I have 2 layers with multi-query attention and noise-injected expert routing. My training produces specialized reasoning patterns!"
            },
            claude: {
                name: 'Claude',
                color: '#d97706',
                greeting: "Hi! I'm Mini Claude with ~35K parameters using Constitutional AI simulation (d_model=32, n_layers=2). I have GLU gating, harmfulness/helpfulness evaluation heads, and constitutional training. My responses follow safety-oriented patterns!"
            }
        };

        // ============================================================================
        // GIBBERISH RESPONSE GENERATION - Each model has unique "neural patterns"
        // Based on character-level training from nano_AI.py models
        // ============================================================================
        
        const responsePatterns = {
            chatgpt: {
                patterns: [
                    "hel ou tod assis que", "can hep wit prob", "unde stan requ", 
                    "provid inf abo", "woul lik kno", "fee fre ask"
                ],
                connectors: ["and", "to", "with", "for", "about"],
                endings: ["today", "question", "help", "information"]
            },
            grok: {
                patterns: [
                    "thn dif per ang", "unc per que int", "cre sol tot dif",
                    "app fro sid way", "exp alt vie", "bre con thi"
                ],
                connectors: ["but", "alt", "diff", "new", "fresh"],
                endings: ["perspective", "angle", "approach", "way"]
            },
            gemini: {
                patterns: [
                    "ana com pre tex", "mul mod tas tog", "und inp fro",
                    "pro dif typ inf", "exp ste ste", "vis tex tog"
                ],
                connectors: ["together", "combined", "multi", "comprehensive"],
                endings: ["analysis", "understanding", "processing", "step"]
            },
            deepseek: {
                patterns: [
                    "pro spe rea mod", "app foc exp", "adv rea cap",
                    "bre dow sys", "det ana sit", "exp rou opt"
                ],
                connectors: ["through", "via", "using", "applying"],
                endings: ["reasoning", "analysis", "systematically", "expertise"]
            },
            claude: {
                patterns: [
                    "hel har hon res", "saf acc gui", "tho imp top",
                    "con req add", "bal eth res", "car ful con"
                ],
                connectors: ["while", "ensuring", "with", "considering"],
                endings: ["safely", "ethically", "thoughtfully", "responsibly"]
            }
        };

        function generateGibberishResponse(userMessage, modelType) {
            const patterns = responsePatterns[modelType];
            if (!patterns) return "Unknown model response";
            
            // Create pseudo-neural response based on input length and model type
            const inputLength = userMessage.length;
            const responseLength = Math.min(Math.max(inputLength, 20), 60);
            
            let response = "";
            let currentLength = 0;
            
            while (currentLength < responseLength) {
                // Pick random pattern
                const pattern = patterns.patterns[Math.floor(Math.random() * patterns.patterns.length)];
                response += pattern;
                currentLength += pattern.length;
                
                // Add connector
                if (currentLength < responseLength - 10) {
                    const connector = patterns.connectors[Math.floor(Math.random() * patterns.connectors.length)];
                    response += " " + connector + " ";
                    currentLength += connector.length + 2;
                }
            }
            
            // Add model-specific ending
            const ending = patterns.endings[Math.floor(Math.random() * patterns.endings.length)];
            response += " " + ending;
            
            return `üß† [MINI-${modelType.toUpperCase()} Neural Output]: ${response}`;
        }

        async function generateResponse(userMessage, modelType) {
            // Simulate network delay like real API
            await new Promise(resolve => setTimeout(resolve, 500 + Math.random() * 1000));
            
            return generateGibberishResponse(userMessage, modelType);
        }

        // ============================================================================
        // GLOBAL CHAT FUNCTIONS - MUST BE GLOBAL FOR ONCLICK HANDLERS
        // ============================================================================
        
        function openChat(modelType) {
            console.log('üöÄ Opening chat for:', modelType);
            currentModel = modelType;
            const config = modelConfigs[modelType];
            
            document.documentElement.style.setProperty('--chat-color', config.color);
            document.getElementById('chatTitle').textContent = `Chat with Mini ${config.name}`;
            
            if (!chatHistory[modelType]) {
                chatHistory[modelType] = [];
                addMessage('bot', config.greeting, modelType);
            }
            
            displayChatHistory(modelType);
            document.getElementById('chatModal').style.display = 'block';
            document.getElementById('chatInput').focus();
        }

        function closeChat() {
            console.log('üö™ Closing chat');
            document.getElementById('chatModal').style.display = 'none';
            currentModel = '';
        }

        function sendMessage() {
            console.log('üì§ Sending message');
            const input = document.getElementById('chatInput');
            const message = input.value.trim();
            
            if (message && currentModel) {
                addMessage('user', message);
                input.value = '';
                
                showTypingIndicator();
                document.getElementById('sendBtn').disabled = true;
                
                generateResponse(message, currentModel)
                    .then(response => {
                        hideTypingIndicator();
                        addMessage('bot', response);
                        document.getElementById('sendBtn').disabled = false;
                        input.focus();
                    })
                    .catch(error => {
                        console.error('üí• Response error:', error);
                        hideTypingIndicator();
                        addMessage('bot', `Error: ${error.message}`);
                        document.getElementById('sendBtn').disabled = false;
                        input.focus();
                    });
            }
        }

        // ============================================================================
        // HELPER FUNCTIONS
        // ============================================================================
        
        function displayChatHistory(modelType) {
            const messagesContainer = document.getElementById('chatMessages');
            messagesContainer.innerHTML = '';
            
            if (chatHistory[modelType]) {
                chatHistory[modelType].forEach(msg => {
                    addMessageToDOM(msg.type, msg.content);
                });
            }
            
            scrollToBottom();
        }

        function addMessage(type, content, modelType = currentModel) {
            if (!chatHistory[modelType]) {
                chatHistory[modelType] = [];
            }
            
            chatHistory[modelType].push({ type, content });
            
            if (modelType === currentModel) {
                addMessageToDOM(type, content);
                scrollToBottom();
            }
        }

        function addMessageToDOM(type, content) {
            const messagesContainer = document.getElementById('chatMessages');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;
            
            const bubbleDiv = document.createElement('div');
            bubbleDiv.className = 'message-bubble';
            bubbleDiv.textContent = content;
            
            messageDiv.appendChild(bubbleDiv);
            messagesContainer.appendChild(messageDiv);
        }

        function showTypingIndicator() {
            document.getElementById('typingIndicator').style.display = 'block';
            scrollToBottom();
        }

        function hideTypingIndicator() {
            document.getElementById('typingIndicator').style.display = 'none';
        }

        function scrollToBottom() {
            const messagesContainer = document.getElementById('chatMessages');
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
        }

        // ============================================================================
        // EVENT LISTENERS AND INITIALIZATION
        // ============================================================================
        
        document.addEventListener('DOMContentLoaded', function() {
            console.log('üöÄ AI Models Showcase loaded, initializing...');
            
            // Add Enter key support for chat input
            document.getElementById('chatInput').addEventListener('keypress', function(e) {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    sendMessage();
                }
            });
            
            // Close modal when clicking outside
            document.getElementById('chatModal').addEventListener('click', function(e) {
                if (e.target === this) {
                    closeChat();
                }
            });
            
            console.log('‚úÖ All mini AI models ready for demonstration!');
            console.log('ü§ñ Available models:', Object.keys(modelConfigs));
        });

        // Make functions globally available
        window.openChat = openChat;
        window.closeChat = closeChat;
        window.sendMessage = sendMessage;
        
        console.log('üéØ AI Models Interface Ready!');
    </script>
</body>
</html>

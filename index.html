<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Models Architecture Showcase</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
            line-height: 1.6;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }

        .header {
            text-align: center;
            margin-bottom: 3rem;
            color: white;
        }

        .header h1 {
            font-size: 3rem;
            font-weight: 700;
            margin-bottom: 1rem;
        }

        .header p {
            font-size: 1.2rem;
            opacity: 0.9;
            max-width: 600px;
            margin: 0 auto;
        }

        .models-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
            gap: 2rem;
        }

        .model-card {
            background: white;
            border-radius: 16px;
            overflow: hidden;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
            transition: transform 0.3s ease;
        }

        .model-card:hover {
            transform: translateY(-5px);
        }

        .card-header {
            padding: 2rem;
            background: var(--primary-color);
            color: white;
            text-align: center;
        }

        .model-icon {
            font-size: 3rem;
            margin-bottom: 1rem;
        }

        .model-title {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        .model-company {
            font-size: 1rem;
            opacity: 0.9;
            margin-bottom: 1rem;
        }

        .architecture-type {
            background: rgba(255, 255, 255, 0.2);
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 500;
        }

        .card-content {
            padding: 2rem;
        }

        .description {
            font-size: 1rem;
            margin-bottom: 2rem;
            color: #555;
        }

        .section {
            margin-bottom: 2rem;
        }

        .section-title {
            font-size: 1.2rem;
            font-weight: 600;
            color: var(--primary-color);
            margin-bottom: 1rem;
            border-bottom: 2px solid var(--primary-color);
            padding-bottom: 0.5rem;
        }

        .process-flow {
            background: #f8fafc;
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
        }

        .flow-step {
            display: flex;
            align-items: center;
            padding: 1rem;
            margin-bottom: 0.5rem;
            background: white;
            border-radius: 8px;
            border-left: 4px solid var(--primary-color);
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        .step-number {
            background: var(--primary-color);
            color: white;
            width: 32px;
            height: 32px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 1rem;
            font-weight: 600;
            font-size: 0.9rem;
        }

        .step-text {
            font-size: 0.95rem;
            font-weight: 500;
        }

        .innovations-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
            gap: 1rem;
        }

        .innovation-card {
            background: #f8fafc;
            padding: 1.5rem;
            border-radius: 12px;
            border-top: 4px solid var(--primary-color);
        }

        .innovation-title {
            font-size: 1rem;
            font-weight: 600;
            color: var(--primary-color);
            margin-bottom: 0.5rem;
        }

        .innovation-desc {
            font-size: 0.9rem;
            color: #666;
        }

        .specs-table {
            background: #f8fafc;
            border-radius: 12px;
            overflow: hidden;
            margin-bottom: 1.5rem;
        }

        .specs-table table {
            width: 100%;
            border-collapse: collapse;
        }

        .specs-table th {
            background: var(--primary-color);
            color: white;
            padding: 1rem;
            text-align: left;
            font-weight: 600;
        }

        .specs-table td {
            padding: 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .specs-table tr:nth-child(even) {
            background: white;
        }

        .chat-button {
            background: var(--primary-color);
            color: white;
            border: none;
            padding: 1rem 2rem;
            border-radius: 25px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            width: 100%;
            transition: all 0.3s ease;
        }

        .chat-button:hover {
            transform: scale(1.05);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.2);
        }

        /* Model-specific colors */
        .chatgpt { --primary-color: #10a37f; }
        .grok { --primary-color: #1d9bf0; }
        .gemini { --primary-color: #4285f4; }
        .deepseek { --primary-color: #ff6b6b; }
        .claude { --primary-color: #d97706; }

        /* Chat Modal */
        .chat-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            z-index: 1000;
        }

        .chat-container {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 90%;
            max-width: 700px;
            height: 80vh;
            background: white;
            border-radius: 16px;
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .chat-header {
            background: var(--chat-color, #333);
            color: white;
            padding: 1.5rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .chat-header h3 {
            font-size: 1.3rem;
            font-weight: 600;
        }

        .close-btn {
            background: none;
            border: none;
            color: white;
            font-size: 1.5rem;
            cursor: pointer;
            padding: 0.5rem;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .close-btn:hover {
            background: rgba(255, 255, 255, 0.2);
        }

        .chat-messages {
            flex: 1;
            padding: 1.5rem;
            overflow-y: auto;
            background: #f8fafc;
        }

        .message {
            margin-bottom: 1rem;
        }

        .message.user {
            text-align: right;
        }

        .message-bubble {
            display: inline-block;
            max-width: 70%;
            padding: 1rem 1.5rem;
            border-radius: 20px;
            font-size: 0.95rem;
        }

        .message.user .message-bubble {
            background: var(--chat-color, #333);
            color: white;
            border-bottom-right-radius: 5px;
        }

        .message.bot .message-bubble {
            background: white;
            color: #333;
            border-bottom-left-radius: 5px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        .chat-input-container {
            padding: 1.5rem;
            background: white;
            border-top: 1px solid #e2e8f0;
        }

        .chat-input-group {
            display: flex;
            gap: 1rem;
        }

        .chat-input {
            flex: 1;
            padding: 0.75rem 1rem;
            border: 2px solid #e2e8f0;
            border-radius: 25px;
            outline: none;
            font-size: 0.95rem;
        }

        .chat-input:focus {
            border-color: var(--chat-color, #333);
        }

        .send-btn {
            background: var(--chat-color, #333);
            color: white;
            border: none;
            padding: 0.75rem 1.5rem;
            border-radius: 25px;
            cursor: pointer;
            font-weight: 600;
        }

        .send-btn:hover {
            opacity: 0.9;
        }

        .typing-indicator {
            display: none;
            padding: 1rem 1.5rem;
            color: #666;
            font-style: italic;
        }

        @media (max-width: 768px) {
            .models-grid {
                grid-template-columns: 1fr;
            }
            
            .header h1 {
                font-size: 2rem;
            }
            
            .innovations-grid {
                grid-template-columns: 1fr;
        function openChat(modelType) {
            currentModel = modelType;
            const config = modelConfigs[modelType];
            
            document.documentElement.style.setProperty('--chat-color', config.color);
            document.getElementById('chatTitle').textContent = `Chat with Mini ${config.name}`;
            
            if (!chatHistory[modelType]) {
                chatHistory[modelType] = [];
                addMessage('bot', config.greeting, modelType);
            }
            
            displayChatHistory(modelType);
            document.getElementById('chatModal').style.display = 'block';
            document.getElementById('chatInput').focus();
        }

        function closeChat() {
            document.getElementById('chatModal').style.display = 'none';
            currentModel = '';
        }

        function displayChatHistory(modelType) {
            const messagesContainer = document.getElementById('chatMessages');
            messagesContainer.innerHTML = '';
            
            if (chatHistory[modelType]) {
                chatHistory[modelType].forEach(msg => {
                    addMessageToDOM(msg.type, msg.content);
                });
            }
            
            scrollToBottom();
        }

        function addMessage(type, content, modelType = currentModel) {
            if (!chatHistory[modelType]) {
                chatHistory[modelType] = [];
            }
            
            chatHistory[modelType].push({ type, content });
            
            if (modelType === currentModel) {
                addMessageToDOM(type, content);
                scrollToBottom();
            }
        }

        function addMessageToDOM(type, content) {
            const messagesContainer = document.getElementById('chatMessages');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;
            
            const bubbleDiv = document.createElement('div');
            bubbleDiv.className = 'message-bubble';
            bubbleDiv.textContent = content;
            
            messageDiv.appendChild(bubbleDiv);
            messagesContainer.appendChild(messageDiv);
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>🤖 AI Architecture Showcase</h1>
            <p>Explore the unique architectures behind the world's most advanced AI systems</p>
        </div>

        <div class="models-grid">
            <!-- ChatGPT -->
            <div class="model-card chatgpt">
                <div class="card-header">
                    <div class="model-icon">🧠</div>
                    <div class="model-title">ChatGPT</div>
                    <div class="model-company">OpenAI</div>
                    <div class="architecture-type">Decoder-only Transformer + RLHF</div>
                </div>
                <div class="card-content">
                    <div class="description">
                        Revolutionary conversational AI using GPT's autoregressive architecture enhanced with Reinforcement Learning from Human Feedback (RLHF) for alignment and safety.
                    </div>

                    <div class="section">
                        <div class="section-title">🏗️ Architecture Flow</div>
                        <div class="process-flow">
                            <div class="flow-step">
                                <div class="step-number">1</div>
                                <div class="step-text">Input Token Embedding + Positional Encoding</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">2</div>
                                <div class="step-text">Pre-LayerNorm → Multi-Head Self-Attention</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">3</div>
                                <div class="step-text">Residual Connection + Pre-LayerNorm</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">4</div>
                                <div class="step-text">Feed-Forward Network (GELU Activation)</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">5</div>
                                <div class="step-text">Output Layer → Next Token Prediction</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">🔧 Key Innovations</div>
                        <div class="innovations-grid">
                            <div class="innovation-card">
                                <div class="innovation-title">Pre-Layer Normalization</div>
                                <div class="innovation-desc">Applies LayerNorm before attention/FFN blocks for better gradient flow and training stability.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">GELU Activation</div>
                                <div class="innovation-desc">Gaussian Error Linear Units provide smoother, probabilistic activation compared to ReLU.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">RLHF Training</div>
                                <div class="innovation-desc">Reinforcement Learning from Human Feedback aligns model outputs with human preferences.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Causal Masking</div>
                                <div class="innovation-desc">Ensures autoregressive generation - each token only attends to previous tokens.</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">📊 Technical Specifications</div>
                        <div class="specs-table">
                            <table>
                                <thead>
                                    <tr>
                                        <th>Component</th>
                                        <th>Specification</th>
                                        <th>Purpose</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Architecture</td>
                                        <td>Decoder-only Transformer</td>
                                        <td>Autoregressive text generation</td>
                                    </tr>
                                    <tr>
                                        <td>Attention</td>
                                        <td>Multi-head self-attention</td>
                                        <td>Learn token relationships</td>
                                    </tr>
                                    <tr>
                                        <td>Activation</td>
                                        <td>GELU</td>
                                        <td>Smooth, probabilistic activation</td>
                                    </tr>
                                    <tr>
                                        <td>Training</td>
                                        <td>Supervised + RLHF</td>
                                        <td>Human alignment & safety</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <button class="chat-button" onclick="openChat('chatgpt')">Chat with Mini ChatGPT</button>
                </div>
            </div>

            <!-- Grok -->
            <div class="model-card grok">
                <div class="card-header">
                    <div class="model-icon">⚡</div>
                    <div class="model-title">Grok</div>
                    <div class="model-company">xAI</div>
                    <div class="architecture-type">Mixture of Experts (MoE)</div>
                </div>
                <div class="card-content">
                    <div class="description">
                        Elon Musk's unconventional AI using Mixture of Experts architecture for efficient scaling. Routes different query types to specialized expert networks dynamically.
                    </div>

                    <div class="section">
                        <div class="section-title">⚡ MoE Architecture Flow</div>
                        <div class="process-flow">
                            <div class="flow-step">
                                <div class="step-number">1</div>
                                <div class="step-text">Input Token → Gating Network Analysis</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">2</div>
                                <div class="step-text">Top-K Expert Selection (K=2)</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">3</div>
                                <div class="step-text">Parallel Expert Processing</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">4</div>
                                <div class="step-text">Weighted Expert Output Combination</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">5</div>
                                <div class="step-text">Load Balancing & Final Output</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">🔧 Key Innovations</div>
                        <div class="innovations-grid">
                            <div class="innovation-card">
                                <div class="innovation-title">Expert Routing</div>
                                <div class="innovation-desc">Gating network selects top-k experts for each token, enabling specialization without full activation.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Sparse Activation</div>
                                <div class="innovation-desc">Only 2-8 experts activate per token, achieving massive scale with constant compute cost.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Load Balancing</div>
                                <div class="innovation-desc">Auxiliary loss ensures experts are utilized evenly, preventing expert collapse.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Specialized Knowledge</div>
                                <div class="innovation-desc">Different experts learn different domains (math, code, reasoning, creativity).</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">📊 Technical Specifications</div>
                        <div class="specs-table">
                            <table>
                                <thead>
                                    <tr>
                                        <th>Component</th>
                                        <th>Configuration</th>
                                        <th>Benefit</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Experts</td>
                                        <td>8-64 specialist networks</td>
                                        <td>Domain specialization</td>
                                    </tr>
                                    <tr>
                                        <td>Routing</td>
                                        <td>Top-K selection (K=2)</td>
                                        <td>Efficient computation</td>
                                    </tr>
                                    <tr>
                                        <td>Gating</td>
                                        <td>Learnable router network</td>
                                        <td>Dynamic expert selection</td>
                                    </tr>
                                    <tr>
                                        <td>Scaling</td>
                                        <td>Constant compute, more experts</td>
                                        <td>Massive capacity growth</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <button class="chat-button" onclick="openChat('grok')">Chat with Mini Grok</button>
                </div>
            </div>

            <!-- Gemini -->
            <div class="model-card gemini">
                <div class="card-header">
                    <div class="model-icon">💎</div>
                    <div class="model-title">Gemini</div>
                    <div class="model-company">Google</div>
                    <div class="architecture-type">Multimodal Transformer</div>
                </div>
                <div class="card-content">
                    <div class="description">
                        Google's most capable multimodal AI, natively processing text, images, audio, and code. Uses advanced attention mechanisms for efficiency and multimodal understanding.
                    </div>

                    <div class="section">
                        <div class="section-title">💎 Multimodal Architecture Flow</div>
                        <div class="process-flow">
                            <div class="flow-step">
                                <div class="step-number">1</div>
                                <div class="step-text">Multimodal Input Processing</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">2</div>
                                <div class="step-text">Multi-Query Attention (Shared K,V)</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">3</div>
                                <div class="step-text">SwiGLU Activation Processing</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">4</div>
                                <div class="step-text">Rotary Position Encoding</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">5</div>
                                <div class="step-text">Unified Multimodal Output</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">🔧 Key Innovations</div>
                        <div class="innovations-grid">
                            <div class="innovation-card">
                                <div class="innovation-title">Multi-Query Attention</div>
                                <div class="innovation-desc">Shared key/value projections across attention heads reduce memory and increase inference speed.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">SwiGLU Activation</div>
                                <div class="innovation-desc">Swish-Gated Linear Units combine sigmoid gating with Swish activation for better performance.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">RoPE Encoding</div>
                                <div class="innovation-desc">Rotary Position Encoding provides better length generalization and relative position understanding.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Native Multimodality</div>
                                <div class="innovation-desc">Joint training on text, images, audio from the start, not adapters or separate encoders.</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">📊 Architecture Improvements</div>
                        <div class="specs-table">
                            <table>
                                <thead>
                                    <tr>
                                        <th>Innovation</th>
                                        <th>Traditional</th>
                                        <th>Gemini Improvement</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Attention</td>
                                        <td>Multi-head (separate K,V)</td>
                                        <td>Multi-query (shared K,V)</td>
                                    </tr>
                                    <tr>
                                        <td>Position</td>
                                        <td>Absolute encoding</td>
                                        <td>Rotary Position Encoding</td>
                                    </tr>
                                    <tr>
                                        <td>Activation</td>
                                        <td>ReLU/GELU</td>
                                        <td>SwiGLU (gated activation)</td>
                                    </tr>
                                    <tr>
                                        <td>Modality</td>
                                        <td>Text-only, then adapted</td>
                                        <td>Native multimodal training</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <button class="chat-button" onclick="openChat('gemini')">Chat with Mini Gemini</button>
                </div>
            </div>

            <!-- DeepSeek -->
            <div class="model-card deepseek">
                <div class="card-header">
                    <div class="model-icon">🔍</div>
                    <div class="model-title">DeepSeek</div>
                    <div class="model-company">DeepSeek AI</div>
                    <div class="architecture-type">Optimized MoE</div>
                </div>
                <div class="card-content">
                    <div class="description">
                        China's advanced reasoning model with heavily optimized Mixture of Experts. Features superior load balancing and expert utilization for mathematical and logical reasoning.
                    </div>

                    <div class="section">
                        <div class="section-title">🔍 Optimized MoE Flow</div>
                        <div class="process-flow">
                            <div class="flow-step">
                                <div class="step-number">1</div>
                                <div class="step-text">Input + Noise Injection (Training)</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">2</div>
                                <div class="step-text">Load-Balanced Expert Selection</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">3</div>
                                <div class="step-text">Expert Processing (SiLU Activation)</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">4</div>
                                <div class="step-text">Usage Tracking & Auxiliary Loss</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">5</div>
                                <div class="step-text">Weighted Expert Output Combination</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">🔧 Key Innovations</div>
                        <div class="innovations-grid">
                            <div class="innovation-card">
                                <div class="innovation-title">Load Balancing</div>
                                <div class="innovation-desc">Advanced algorithms ensure all experts are utilized evenly, preventing dead experts and improving capacity.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Noise Injection</div>
                                <div class="innovation-desc">Adds noise to gating logits during training to encourage exploration and better expert utilization.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">SiLU Throughout</div>
                                <div class="innovation-desc">Sigmoid Linear Units (Swish) activation used consistently for smooth, differentiable activations.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Reasoning Focus</div>
                                <div class="innovation-desc">Specialized training and expert allocation for mathematical, logical, and step-by-step reasoning tasks.</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">📊 Optimization Solutions</div>
                        <div class="specs-table">
                            <table>
                                <thead>
                                    <tr>
                                        <th>Optimization</th>
                                        <th>Problem Solved</th>
                                        <th>Method</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Expert Collapse</td>
                                        <td>Some experts never used</td>
                                        <td>Load balancing loss</td>
                                    </tr>
                                    <tr>
                                        <td>Poor Exploration</td>
                                        <td>Limited expert diversity</td>
                                        <td>Training noise injection</td>
                                    </tr>
                                    <tr>
                                        <td>Reasoning Quality</td>
                                        <td>Weak mathematical logic</td>
                                        <td>Specialized expert training</td>
                                    </tr>
                                    <tr>
                                        <td>Efficiency</td>
                                        <td>Wasted computation</td>
                                        <td>Dynamic expert allocation</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <button class="chat-button" onclick="openChat('deepseek')">Chat with Mini DeepSeek</button>
                </div>
            </div>

            <!-- Claude -->
            <div class="model-card claude">
                <div class="card-header">
                    <div class="model-icon">🎭</div>
                    <div class="model-title">Claude</div>
                    <div class="model-company">Anthropic</div>
                    <div class="architecture-type">Constitutional AI</div>
                </div>
                <div class="card-content">
                    <div class="description">
                        Anthropic's safety-focused AI built with Constitutional AI principles. Features advanced gating mechanisms and built-in harmlessness evaluation for responsible AI behavior.
                    </div>

                    <div class="section">
                        <div class="section-title">🎭 Constitutional AI Flow</div>
                        <div class="process-flow">
                            <div class="flow-step">
                                <div class="step-number">1</div>
                                <div class="step-text">Input Safety Assessment</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">2</div>
                                <div class="step-text">GLU-Gated Processing</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">3</div>
                                <div class="step-text">Constitutional Principles Check</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">4</div>
                                <div class="step-text">Response Generation</div>
                            </div>
                            <div class="flow-step">
                                <div class="step-number">5</div>
                                <div class="step-text">Harmlessness Verification</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">🔧 Key Innovations</div>
                        <div class="innovations-grid">
                            <div class="innovation-card">
                                <div class="innovation-title">GLU Activation</div>
                                <div class="innovation-desc">Gated Linear Units provide controllable information flow with learnable gating mechanisms.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Constitutional Training</div>
                                <div class="innovation-desc">Self-supervised learning from a constitution of principles for helpful, harmless, honest behavior.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Safety Scoring</div>
                                <div class="innovation-desc">Built-in harmfulness and helpfulness evaluation heads for real-time safety assessment.</div>
                            </div>
                            <div class="innovation-card">
                                <div class="innovation-title">Principle-Based</div>
                                <div class="innovation-desc">Responses generated based on explicit constitutional principles rather than just human feedback.</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">📊 Constitutional Principles</div>
                        <div class="specs-table">
                            <table>
                                <thead>
                                    <tr>
                                        <th>Constitutional Principle</th>
                                        <th>Implementation</th>
                                        <th>Safety Benefit</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Helpfulness</td>
                                        <td>Dedicated scoring head</td>
                                        <td>Maximizes user utility</td>
                                    </tr>
                                    <tr>
                                        <td>Harmlessness</td>
                                        <td>Safety evaluation layer</td>
                                        <td>Prevents harmful outputs</td>
                                    </tr>
                                    <tr>
                                        <td>Honesty</td>
                                        <td>Uncertainty quantification</td>
                                        <td>Reduces hallucinations</td>
                                    </tr>
                                    <tr>
                                        <td>Transparency</td>
                                        <td>Explainable reasoning</td>
                                        <td>Auditable decisions</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <button class="chat-button" onclick="openChat('claude')">Chat with Mini Claude</button>
                </div>
            </div>
        </div>
    </div>

    <!-- Chat Modal -->
    <div id="chatModal" class="chat-modal">
        <div class="chat-container">
            <div class="chat-header">
                <h3 id="chatTitle">Chat with AI</h3>
                <button class="close-btn" onclick="closeChat()">&times;</button>
            </div>
            <div class="chat-messages" id="chatMessages"></div>
            <div class="typing-indicator" id="typingIndicator">
                <span>AI is thinking...</span>
            </div>
            <div class="chat-input-container">
                <div class="chat-input-group">
                    <input type="text" class="chat-input" id="chatInput" placeholder="Type your message..." onkeypress="handleKeyPress(event)">
                    <button class="send-btn" id="sendBtn" onclick="sendMessage()">Send</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        let currentModel = '';
        const chatHistory = {};

        // Simple tokenizer (ported from Python)
        class SimpleTokenizer {
            constructor() {
                this.charToIdx = {};
                this.idxToChar = {};
                this.vocabSize = 0;
            }
            
            fit(text) {
                const chars = [...new Set(text)].sort();
                this.vocabSize = chars.length;
                this.charToIdx = Object.fromEntries(chars.map((ch, i) => [ch, i]));
                this.idxToChar = Object.fromEntries(chars.map((ch, i) => [i, ch]));
            }
            
            encode(text) {
                return text.split('').map(ch => this.charToIdx[ch] || 0);
            }
            
            decode(tokens) {
                return tokens.map(tok => this.idxToChar[tok] || '<UNK>').join('');
            }
        }

        // Miniature AI Models (ported from Python)
        class MiniAIModel {
            constructor(modelType) {
                this.modelType = modelType;
                this.tokenizer = new SimpleTokenizer();
                this.initializeModel();
            }
            
            initializeModel() {
                // Initialize with training data based on model type
                const trainingData = this.getTrainingData();
                this.tokenizer.fit(trainingData);
                this.isInitialized = true;
            }
            
            getTrainingData() {
                const data = {
                    chatgpt: "Hello! How can I help you today? I'm here to assist with any questions you have. What would you like to know about? I can help with explanations, writing, and problem-solving. Feel free to ask me anything!",
                    grok: "Let me think about this differently. Here's an unconventional perspective on that question. That's an interesting way to look at it! I love exploring creative solutions to problems. What if we approached this from a totally different angle?",
                    gemini: "I can help you with text, images, and multimodal tasks. Let me analyze this comprehensively for you. Here's what I understand from your input. I can process different types of information together. Would you like me to explain this step by step?",
                    deepseek: "Let me process this through my specialized reasoning modules. I'll apply focused expertise to solve this problem. Using advanced reasoning capabilities for this task. Let me break this down systematically. Here's my detailed analysis of the situation.",
                    claude: "I want to be helpful, harmless, and honest in my response. Let me make sure my answer is both accurate and safe. I'll be thoughtful about the implications of this topic. Is there anything concerning about this request I should address? I aim to provide balanced and ethical guidance."
                };

        // Updated to use your deployed API
        async function generateResponse(userMessage, modelType) {
            try {
                // Replace with YOUR actual deployment URL
                const API_URL = 'https://YOUR-DEPLOYMENT-URL-HERE.com';  // 👈 CHANGE THIS!
                
                const response = await fetch(`${API_URL}/chat`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        model: modelType,
                        message: userMessage
                    })
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                
                const data = await response.json();
                
                // Return the REAL neural network output
                return `🧠 [${modelType.toUpperCase()} Real Neural Output]: ${data.response}`;
                
            } catch (error) {
                console.error('Error calling Python API:', error);
                
                // Enhanced fallback message
                return `❌ Could not connect to Python API.

🔗 **Current API URL:** ${API_URL || 'Not set'}
📍 **Expected endpoint:** ${API_URL}/chat

✅ **To fix this:**
1. Make sure your Flask API is deployed and running
2. Update the API_URL in the HTML code with your actual deployment URL
3. Test your API by visiting: ${API_URL}/health

🌐 **GitHub Pages:** https://gghimire2041.github.io/Nano-AI/
📂 **Your repo:** https://github.com/gghimire2041/Nano-AI

💡 **Common deployment URLs:**
• Railway: https://nano-ai-production-xyz.up.railway.app
• Render: https://nano-ai-xyz.onrender.com  
• Vercel: https://nano-ai-xyz.vercel.app
• Heroku: https://nano-ai-xyz.herokuapp.com`;
            }
        }
                return data[this.modelType] || data.chatgpt;
            }
            
            generateResponse(prompt, maxLength = 50) {
                // Simulate model-specific processing
                const responses = this.getModelResponses();
                const contextualResponses = this.getContextualResponses(prompt);
                
                // Check for specific query types
                if (prompt.toLowerCase().includes('architecture') || prompt.toLowerCase().includes('how do you work')) {
                    return this.getArchitectureResponse();
                }
                
                if (prompt.toLowerCase().includes('what are you') || prompt.toLowerCase().includes('who are you')) {
                    return this.getIdentityResponse();
                }
                
                // For complex queries
                if (prompt.length > 100 || this.isComplexQuery(prompt)) {
                    return this.getComplexQueryResponse();
                }
                
                // Generate contextual response
                let response = this.selectBestResponse(prompt, [...responses, ...contextualResponses]);
                
                // Add model-specific processing indicators
                return this.addProcessingContext(response);
            }
            
            getModelResponses() {
                const responses = {
                    chatgpt: [
                        "That's a great question! Let me help you understand this concept.",
                        "I'd be happy to explain that for you using my transformer architecture.",
                        "Based on my RLHF training, here's what I can tell you about this topic.",
                        "Let me break this down in a clear and helpful way.",
                        "I can provide some insights on this subject through my neural networks.",
                        "Excellent question! My pre-layer normalization is processing this.",
                        "Drawing from my training data, I can help with this.",
                        "My GELU activations are working on a comprehensive response.",
                        "Let me use my causal attention to address your query.",
                        "Perfect! My autoregressive generation can help explain this."
                    ],
                    grok: [
                        "Ah, now that's an interesting angle! Let me flip this upside down for you.",
                        "Here's a rebellious take on your question that might surprise you.",
                        "Time to activate unconventional thinking mode!",
                        "Let me route this through my most creative expert networks.",
                        "Plot twist incoming - here's a perspective you probably haven't considered.",
                        "My expert gating is selecting the most unconventional approach.",
                        "Sparse activation engaged! Only my wildest experts are firing.",
                        "Time for some serious out-of-the-box expert routing.",
                        "My top-k selection just picked the most creative experts.",
                        "Load balancing complete - routing to my rebellious knowledge domains."
                    ],
                    gemini: [
                        "Processing this through my multimodal understanding capabilities.",
                        "Let me analyze this systematically across multiple dimensions.",
                        "My advanced reasoning engines are working on this comprehensively.",
                        "Applying multi-query attention to understand all aspects of your question.",
                        "Using my SwiGLU activations to process this efficiently.",
                        "My shared K,V projections are optimizing this analysis.",
                        "RoPE encoding is helping me understand the relationships here.",
                        "Multimodal processing engaged for comprehensive understanding.",
                        "My attention heads are collaborating on this query.",
                        "Rotary position encoding is enhancing my contextual awareness."
                    ],
                    deepseek: [
                        "Engaging specialized reasoning modules for systematic analysis.",
                        "Applying load-balanced expert selection for optimal processing.",
                        "My mathematical reasoning experts are collaborating on this.",
                        "Processing through optimized MoE architecture for deep understanding.",
                        "Using step-by-step logical reasoning to address your query.",
                        "Noise injection complete - experts are exploring all possibilities.",
                        "SiLU activations are providing smooth gradient flow for this analysis.",
                        "My auxiliary loss is ensuring balanced expert utilization.",
                        "Load balancing algorithms are selecting optimal reasoning pathways.",
                        "Deep reasoning modules are conducting systematic exploration."
                    ],
                    claude: [
                        "I want to provide a helpful and responsible response to your question.",
                        "Let me ensure my answer is both accurate and ethically sound.",
                        "Processing this through my Constitutional AI principles.",
                        "I'll provide a balanced perspective while being mindful of safety.",
                        "My harmlessness scoring indicates this is appropriate to discuss.",
                        "GLU gating mechanisms are ensuring controlled information flow.",
                        "Constitutional training is guiding my response generation.",
                        "Safety-first architecture is processing your request thoughtfully.",
                        "My helpfulness evaluation confirms this is a good query to address.",
                        "Principle-based reasoning is generating an appropriate response."
                    ]
                };
                return responses[this.modelType] || responses.chatgpt;
            }
            
            getContextualResponses(prompt) {
                const lower = prompt.toLowerCase();
                const contextual = [];
                
                if (lower.includes('hello') || lower.includes('hi')) {
                    const greetings = {
                        chatgpt: [
                            `Hello! I'm Mini ChatGPT. How can I assist you today?`,
                            `Hi there! I'm ready to help with any questions you have.`,
                            `Greetings! I'm here to provide helpful responses using my RLHF training.`,
                            `Hello! My decoder-only transformer is ready to chat with you.`,
                            `Hi! I'm excited to help you explore AI concepts today.`
                        ],
                        grok: [
                            `Hey! Ready for some unconventional AI insights?`,
                            `Hello there, fellow curious soul! Time to think differently.`,
                            `Hi! My expert networks are buzzing with creative energy.`,
                            `Greetings! Let's explore some rebellious AI perspectives.`,
                            `Hey! My MoE routing is ready for anything you throw at me.`
                        ],
                        gemini: [
                            `Greetings! My multimodal systems are ready for analysis.`,
                            `Hello! I'm processing your greeting through multi-query attention.`,
                            `Hi there! My SwiGLU activations are warmed up and ready.`,
                            `Greetings! Ready for comprehensive, systematic analysis.`,
                            `Hello! My RoPE encoding is helping me understand you perfectly.`
                        ],
                        deepseek: [
                            `Hello! My reasoning modules are primed for deep analysis.`,
                            `Greetings! Load balancing complete - ready for logical exploration.`,
                            `Hi! My expert networks are synchronized for mathematical thinking.`,
                            `Hello! SiLU activations online - let's dive deep together.`,
                            `Greetings! My systematic reasoning capabilities await your questions.`
                        ],
                        claude: [
                            `Hi! I'm here to help in a safe, responsible manner.`,
                            `Hello! My constitutional principles are guiding me to assist you.`,
                            `Greetings! I aim to be helpful, harmless, and honest with you.`,
                            `Hi there! My GLU activations are ensuring ethical responses.`,
                            `Hello! Safety checks complete - ready for thoughtful conversation.`
                        ]
                    };
                    
                    const modelGreetings = greetings[this.modelType] || greetings.chatgpt;
                    contextual.push(modelGreetings[Math.floor(Math.random() * modelGreetings.length)]);
                }
                
                if (lower.includes('thank')) {
                    const thankResponses = {
                        chatgpt: [
                            "You're very welcome! I'm glad I could help.",
                            "My pleasure! Feel free to ask anything else.",
                            "Happy to assist! That's what I'm designed for.",
                            "You're welcome! I enjoy helping users learn."
                        ],
                        grok: [
                            "No problem! My experts enjoyed that challenge.",
                            "You're welcome! Always fun to think outside the box.",
                            "Glad to help! My routing network loved that query.",
                            "Anytime! Unconventional problems are my specialty."
                        ],
                        gemini: [
                            "You're welcome! My multimodal analysis was thorough.",
                            "Happy to help! My attention mechanisms were well-utilized.",
                            "My pleasure! Comprehensive assistance is my goal.",
                            "You're welcome! My efficiency optimizations paid off."
                        ],
                        deepseek: [
                            "You're welcome! My reasoning was systematic and complete.",
                            "Glad to help! My expert networks collaborated well.",
                            "My pleasure! Deep analysis yields better solutions.",
                            "You're welcome! Logical reasoning at your service."
                        ],
                        claude: [
                            "You're very welcome! I'm glad my response was helpful and appropriate.",
                            "My pleasure! I aimed to be both useful and responsible.",
                            "Happy to help! My constitutional training guides me to assist.",
                            "You're welcome! I strive for helpful, ethical responses."
                        ]
                    };
                    
                    const modelThanks = thankResponses[this.modelType] || thankResponses.chatgpt;
                    contextual.push(modelThanks[Math.floor(Math.random() * modelThanks.length)]);
                }
                
                if (lower.includes('explain') || lower.includes('what is')) {
                    const explainResponses = {
                        chatgpt: [
                            "I'd be happy to explain that concept for you!",
                            "Let me break that down in a clear, helpful way.",
                            "Great question! I'll explain this step by step.",
                            "I can definitely help clarify that for you."
                        ],
                        grok: [
                            "Time to explain this with a fresh perspective!",
                            "Let me route this to my most creative explanation experts.",
                            "I'll explain this in a way you've never heard before!",
                            "Perfect! My unconventional explanation mode is activated."
                        ],
                        gemini: [
                            "I'll provide a comprehensive, multi-dimensional explanation.",
                            "Let me analyze this systematically and explain clearly.",
                            "My multimodal understanding will help explain this perfectly.",
                            "I'll process this through multiple attention layers for clarity."
                        ],
                        deepseek: [
                            "Let me apply systematic reasoning to explain this clearly.",
                            "I'll break this down using logical, step-by-step analysis.",
                            "My specialized reasoning experts will explain this thoroughly.",
                            "Perfect! Time for deep, methodical explanation."
                        ],
                        claude: [
                            "I'll explain this thoughtfully and responsibly.",
                            "Let me provide a balanced, accurate explanation.",
                            "I'll ensure my explanation is both helpful and appropriate.",
                            "I'll explain this with care for accuracy and safety."
                        ]
                    };
                    
                    const modelExplains = explainResponses[this.modelType] || explainResponses.chatgpt;
                    contextual.push(modelExplains[Math.floor(Math.random() * modelExplains.length)]);
                }
                
                return contextual;
            }
            
            selectBestResponse(prompt, responses) {
                // Enhanced selection with more variety
                const lower = prompt.toLowerCase();
                
                // For creative/different requests, prioritize creative responses
                if (lower.includes('creative') || lower.includes('different') || lower.includes('unique')) {
                    const creativeResponses = responses.filter(r => 
                        r.includes('creative') || r.includes('unconventional') || 
                        r.includes('different') || r.includes('unique')
                    );
                    if (creativeResponses.length > 0) {
                        return creativeResponses[Math.floor(Math.random() * creativeResponses.length)];
                    }
                }
                
                // For technical requests, prioritize technical responses
                if (lower.includes('technical') || lower.includes('how') || lower.includes('architecture')) {
                    const techResponses = responses.filter(r => 
                        r.includes('technical') || r.includes('process') || 
                        r.includes('architecture') || r.includes('system')
                    );
                    if (techResponses.length > 0) {
                        return techResponses[Math.floor(Math.random() * techResponses.length)];
                    }
                }
                
                // For simple questions, use any response randomly
                if (responses.length > 0) {
                    return responses[Math.floor(Math.random() * responses.length)];
                }
                
                // Fallback
                return "I'm processing your request through my neural networks...";
            }
            
            addProcessingContext(response) {
                const contexts = {
                    chatgpt: "🧠 [Decoder-only Transformer]: ",
                    grok: "⚡ [MoE Expert Routing]: ",
                    gemini: "💎 [Multi-Query Attention]: ",
                    deepseek: "🔍 [Optimized MoE]: ",
                    claude: "🎭 [Constitutional AI]: "
                };
                
                return contexts[this.modelType] + response;
            }
            
            getArchitectureResponse() {
                const architectures = {
                    chatgpt: "I use a decoder-only transformer with pre-layer normalization, GELU activations, and RLHF training. My architecture processes tokens autoregressively, using causal masking to ensure each token only attends to previous tokens.",
                    grok: "I'm built with Mixture of Experts (MoE) architecture. My gating network routes queries to the top-2 most relevant expert networks out of multiple specialists, enabling massive scaling with constant compute cost per token.",
                    gemini: "I use multi-query attention where key and value projections are shared across heads for efficiency. My SwiGLU activations and rotary position encoding enable superior multimodal understanding and processing.",
                    deepseek: "I implement optimized MoE with load balancing to prevent expert collapse, noise injection for better exploration, and SiLU activations throughout for smooth gradient flow and enhanced reasoning.",
                    claude: "I use GLU (Gated Linear Units) for controlled information flow and Constitutional AI training. My architecture includes built-in harmlessness and helpfulness scoring mechanisms for safe, ethical responses."
                };
                return this.addProcessingContext(architectures[this.modelType]);
            }
            
            getIdentityResponse() {
                const identities = {
                    chatgpt: "I'm a miniature implementation of ChatGPT, demonstrating decoder-only transformer architecture with RLHF training. I showcase how autoregressive language models generate text token by token.",
                    grok: "I'm Mini Grok, powered by Mixture of Experts architecture. I demonstrate how different expert networks can specialize in different domains while maintaining efficient computation through sparse activation.",
                    gemini: "I'm Mini Gemini, featuring multi-query attention and multimodal capabilities. I show how shared key-value projections and advanced attention mechanisms enable efficient processing.",
                    deepseek: "I'm Mini DeepSeek, showcasing optimized MoE with advanced load balancing. I demonstrate how sophisticated expert routing and noise injection improve mathematical and logical reasoning.",
                    claude: "I'm Mini Claude, built with Constitutional AI principles. I demonstrate how GLU activations and safety-first architecture enable helpful, harmless, and honest AI behavior."
                };
                return this.addProcessingContext(identities[this.modelType]);
            }
            
            getComplexQueryResponse() {
                return this.addProcessingContext(`I'm just a miniature implementation of ${this.getModelName()} and this question seems quite complex. Please use the full AI system for detailed analysis and comprehensive answers like this!`);
            }
            
            isComplexQuery(prompt) {
                const complexIndicators = ['detailed research', 'comprehensive analysis', 'write a paper', 'full report', 'in-depth study'];
                return complexIndicators.some(indicator => prompt.toLowerCase().includes(indicator));
            }
            
            getModelName() {
                const names = {
                    chatgpt: 'ChatGPT',
                    grok: 'Grok', 
                    gemini: 'Gemini',
                    deepseek: 'DeepSeek',
                    claude: 'Claude'
                };
                return names[this.modelType];
            }
        }

        // Initialize models
        const models = {
            chatgpt: new MiniAIModel('chatgpt'),
            grok: new MiniAIModel('grok'),
            gemini: new MiniAIModel('gemini'),
            deepseek: new MiniAIModel('deepseek'),
            claude: new MiniAIModel('claude')
        };

        const modelConfigs = {
            chatgpt: {
                name: 'ChatGPT',
                color: '#10a37f',
                greeting: "Hello! I'm a miniature version of ChatGPT, demonstrating decoder-only transformer architecture with RLHF training. I can help explain concepts, answer questions, and have conversations. What would you like to explore?"
            },
            grok: {
                name: 'Grok',
                color: '#1d9bf0',
                greeting: "Hey! I'm Mini Grok, powered by Mixture of Experts architecture. My specialized expert networks let me route different types of queries to the most suitable knowledge domains. Ready for some unconventional insights?"
            },
            gemini: {
                name: 'Gemini',
                color: '#4285f4',
                greeting: "Greetings! I'm Mini Gemini, featuring multi-query attention and SwiGLU activations. My architecture is optimized for multimodal understanding and efficient processing. I can analyze complex queries systematically!"
            },
            deepseek: {
                name: 'DeepSeek',
                color: '#ff6b6b',
                greeting: "Hello! I'm Mini DeepSeek, featuring optimized Mixture of Experts with advanced load balancing. My architecture excels at systematic reasoning and mathematical logic. Let's dive deep into your question!"
            },
            claude: {
                name: 'Claude',
                color: '#d97706',
                greeting: "Hi! I'm Mini Claude, built with Constitutional AI principles and GLU activations. My architecture includes built-in safety mechanisms and ethical reasoning capabilities. I aim to be helpful, harmless, and honest!"
            }
        };

        function openChat(modelType) {
            currentModel = modelType;
            const config = modelConfigs[modelType];
            
            document.documentElement.style.setProperty('--chat-color', config.color);
            document.getElementById('chatTitle').textContent = `Chat with Mini ${config.name}`;
            
            if (!chatHistory[modelType]) {
                chatHistory[modelType] = [];
                addMessage('bot', config.greeting, modelType);
            }
            
            displayChatHistory(modelType);
            document.getElementById('chatModal').style.display = 'block';
            document.getElementById('chatInput').focus();
        }

        function closeChat() {
            document.getElementById('chatModal').style.display = 'none';
            currentModel = '';
        }

        function displayChatHistory(modelType) {
            const messagesContainer = document.getElementById('chatMessages');
            messagesContainer.innerHTML = '';
            
            if (chatHistory[modelType]) {
                chatHistory[modelType].forEach(msg => {
                    addMessageToDOM(msg.type, msg.content);
                });
            }
            
            scrollToBottom();
        }

        function addMessage(type, content, modelType = currentModel) {
            if (!chatHistory[modelType]) {
                chatHistory[modelType] = [];
            }
            
            chatHistory[modelType].push({ type, content });
            
            if (modelType === currentModel) {
                addMessageToDOM(type, content);
                scrollToBottom();
            }
        }

        function addMessageToDOM(type, content) {
            const messagesContainer = document.getElementById('chatMessages');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;
            
            const bubbleDiv = document.createElement('div');
            bubbleDiv.className = 'message-bubble';
            bubbleDiv.textContent = content;
            
            messageDiv.appendChild(bubbleDiv);
            messagesContainer.appendChild(messageDiv);
        function sendMessage() {
            const input = document.getElementById('chatInput');
            const message = input.value.trim();
            
            if (message && currentModel) {
                addMessage('user', message);
                input.value = '';
                
                showTypingIndicator();
                document.getElementById('sendBtn').disabled = true;
                
                // Call the async generateResponse function
                generateResponse(message, currentModel).then(response => {
                    hideTypingIndicator();
                    addMessage('bot', response);
                    document.getElementById('sendBtn').disabled = false;
                    input.focus();
                }).catch(error => {
                    console.error('Error generating response:', error);
                    hideTypingIndicator();
                    addMessage('bot', 'Sorry, I encountered an error generating a response.');
                    document.getElementById('sendBtn').disabled = false;
                    input.focus();
                });
            }
        }

        function showTypingIndicator() {
            document.getElementById('typingIndicator').style.display = 'block';
            scrollToBottom();
        }

        function hideTypingIndicator() {
            document.getElementById('typingIndicator').style.display = 'none';
        }

        function scrollToBottom() {
            const messagesContainer = document.getElementById('chatMessages');
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
        }

        function handleKeyPress(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault();
                sendMessage();
            }
        }
            const input = document.getElementById('chatInput');
            const message = input.value.trim();
            
            if (message && currentModel) {
                addMessage('user', message);
                input.value = '';
                
                showTypingIndicator();
                document.getElementById('sendBtn').disabled = true;
                
                // Call the async generateResponse function
                generateResponse(message, currentModel).then(response => {
                    hideTypingIndicator();
                    addMessage('bot', response);
                    document.getElementById('sendBtn').disabled = false;
                    input.focus();
                }).catch(error => {
                    console.error('Error generating response:', error);
                    hideTypingIndicator();
                    addMessage('bot', 'Sorry, I encountered an error generating a response.');
                    document.getElementById('sendBtn').disabled = false;
                    input.focus();
                });
            }
        }

        function generateResponse(userMessage, modelType) {
            // Use the actual AI model to generate response
            const model = models[modelType];
            if (model && model.isInitialized) {
                return model.generateResponse(userMessage);
            }
            
            // Fallback to simple response if model not available
            const config = modelConfigs[modelType];
            return `I'm Mini ${config.name}, but I'm still initializing. Please try again in a moment!`;
        }

        function showTypingIndicator() {
            document.getElementById('typingIndicator').style.display = 'block';
            scrollToBottom();
        }

        function hideTypingIndicator() {
            document.getElementById('typingIndicator').style.display = 'none';
        }

        function scrollToBottom() {
            const messagesContainer = document.getElementById('chatMessages');
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
        }

        function handleKeyPress(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault();
                sendMessage();
            }
        }

        document.getElementById('chatModal').addEventListener('click', function(event) {
            if (event.target === this) {
                closeChat();
            }
        });

        // Initialize all models when page loads
        console.log('🤖 Mini AI Models initialized:', Object.keys(models).map(key => `${models[key].getModelName()} (${key})`).join(', '));
    </script>
</body>
</html>
